---
title: Quantization
draft: false
tags: 
date: 2024-10-01 10:49
---
کوانتایز کردن مدل، تکنیکی برای کاهش حجم و توان مورد نیاز برای اجرای مدل‌هاست. در حین این تکنیک، [[Parameter|پارامترهای مدل]] به نوعی فشرده می‌شوند و در قالب کوچک‌تری قرار می‌گیرند. به عنوان مثال، اگر پارامترهای مدل را اعدادی اعشاری در نظر بگیریم، در حالت عادی برای هر پارامتر ۳۲ بیت حافظه (یعنی ۳۲ خانه که می‌توانند ۰ یا ۱ باشند) اختصاص پیدا می‌کند. مثلاً عدد ۰٫۱۵۶۲۵ به این شکل در کامپیوتر ذخیره می‌شود:


![[Float_example.svg.png]]


> [!question]‌ فرآیند تبدیل عدد به فرمت float32
> برای تبدیل عدد ۰٫۱۵۶۲۵ به متغیر `float32`، به ترتیب مراحل زیر طی می‌شود:
> - اول از همه عدد باید به م[بنای دو](https://www.rapidtables.com/convert/number/decimal-to-binary.html?x=0.15625) برده شود. عدد ۰٫۱۵۶۲۵ در مبنای دو برابر `0.00101` است.
> - عدد حاصل شده باید به صورت ترکیبی از توان و عدد علمی نوشته شود: بخش علمی آن برابر `1.01` و توان آن برابر `-3`‌است.
> - بعد از این دیگر نوبت به جاگذاری مقادیر در قالب `float32` می‌رسد.
> - چون عدد مثبت است، مقدار `sign` برابر `0` می‌شود.
> - مقدار توان به دلیل بایاس ۱۲۷[^1] قالب `float32` برابر ۱۲۴ است که در مبنای دو برابر `01111100` است.
> - مقدار اعشار هم برابر `010`‌است. باقی خانه‌های حافظه بعد از آن هم برابر `0` می‌شود.
> - پس عدد ۰٫۱۵۶۲۵ در قالب `float32` برابر `00111110001000000000000000000000`‌خواهد بود.

اما `float32`‌تنها راه ذخیره‌سازی اعداد در حافظه نیست. فرمت‌های دیگری مثل `float16`‌(`FP16`) یا حتی `int` هم برای این کار وجود دارند. این فرمت‌ها به نسبت `FP32` حجم کمتری برای ذخیرهٔ متغیرها می‌گیرند. مثلاً مقدار ۰٫۱۵۶۲۵ در فرمت `FP16`‌برابر `0011000100000000` خواهد بود که نصف فرمت `FP32` حجم می‌گیرد.

در نتیجهٔ کوانتایز کردن مدل، حجم مدل به شکل قابل توجهی کاهش پیدا می‌کند. به دلیل ساده‌تر شدن ضرب و جمع ماتریسی، سرعت آن هم افزایش پیدا می‌کند. البته که همهٔ این‌ها با ریسک کاهش دقت مدل مواجه است. با این وجود، تجربه نشان داده که دقت مدل‌های کوانتایز شده تفاوتی اساسی با مدل‌های اصلی ندارد. در پایین به عنوان نمونه، جدولی از تفاوت نسخه‌های کوانتایزشدهٔ مدل ۱۲ میلیارد پارامتری [[ساختن مدل و خلق تصویر با Flux|Flux Schnell]] آمده است:

| مدل      | حجم       |
| -------- | --------- |
| Original | `23.8 GB` |
| F16      | `23.8 GB` |
| Q8       | `12.6 GB` |
| Q5       | `8.18 GB` |
| Q4       | `6.69 GB` |
| Q2       | `3.9 GB`  |

| ![[d9f237_2a89a7dfe6134a74a7182caefc36ad73~mv2.png]]                                 |
| ------------------------------------------------------------------------------------ |
| <center>یک نمونه از کوانتایز کردن مقادیر اعشاری و تبدیل آن‌ها به اعداد صحیح</center> |




[^1]: دلیل وجود بایاس این است که از اعداد منفی هم پشتیبانی کند.